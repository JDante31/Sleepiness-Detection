{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project Plan:\n",
    "# 1. Setup or get video input\n",
    "# 2. Build recognition elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Dependencies\n",
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import time\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PoseAnalyzer:\n",
    "\n",
    "    def __init__(self,head_range=(115,130),hip_angle_threshold=45):\n",
    "\n",
    "        self.head_range = head_range\n",
    "        self.hip_angle_threshold = hip_angle_threshold\n",
    "\n",
    "    def calculate_angle(self,a,b,c):\n",
    "        ab = np.array([a.x-b.x,a.y-b.y])\n",
    "        bc = np.array([b.x-c.x,b.y-c.y])\n",
    "\n",
    "        dot_product = np.dot(ab,bc)\n",
    "        magnitude_ab = np.linalg.norm(ab)\n",
    "        magnitude_bc = np.linalg.norm(bc)\n",
    "\n",
    "        cos_angle = dot_product / (magnitude_ab * magnitude_bc)\n",
    "    \n",
    "        angle = np.arccos(np.clip(cos_angle,-1.0,1.0))\n",
    "        angle_deg = np.degrees(angle)\n",
    "\n",
    "        return angle_deg\n",
    "    \n",
    "    def is_head_tilted(self,shoulder_left,shoulder_right,nose):\n",
    "\n",
    "        #Checks if head is tilted, based on the range we consider not tilted\n",
    "        tilt_angle = self.calculate_angle(shoulder_left,shoulder_right,nose)\n",
    "        is_tilted = not (self.head_range[0] <= tilt_angle <= self.head_range[1])\n",
    "        return tilt_angle, is_tilted\n",
    "\n",
    "\n",
    "    def is_standing(self,knee_left,hip_left,shoulder_left,knee_right,hip_right,shoulder_right):\n",
    "        left_hip_angle = self.calculate_angle(knee_left,hip_left,shoulder_left)\n",
    "        right_hip_angle = self.calculate_angle(knee_right,hip_right,shoulder_right)\n",
    "\n",
    "        is_standing = left_hip_angle < self.hip_angle_threshold and right_hip_angle < self.hip_angle_threshold\n",
    "        return left_hip_angle,right_hip_angle,is_standing\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "class EyeStateDetector:\n",
    "\n",
    "    def __init__(self,ear_threshold):\n",
    "        self.ear_threshold = ear_threshold\n",
    "        self.left_eye_closed_start = None\n",
    "        self.right_eye_closed_start = None\n",
    "        self.left_eye_closed_duration = 0\n",
    "        self.right_eye_closed_duration = 0\n",
    "        self.eye_closed_duration = 0\n",
    "\n",
    "    def eye_aspect_ratio(self,eye):\n",
    "        #Vertical landmarks\n",
    "        A = distance.euclidean(eye[1],eye[5])\n",
    "        B = distance.euclidean(eye[2],eye[4])\n",
    "        #Horizontal landmarks\n",
    "        C = distance.euclidean(eye[0],eye[3])\n",
    "        ea_ratio = (A+B)/(2*C)\n",
    "        return ea_ratio\n",
    "\n",
    "    def update_eye_status(self,left_eye,right_eye,current_time):\n",
    "       \n",
    "        #Calculate EAR for both eyes\n",
    "        left_ear = self.eye_aspect_ratio(left_eye)\n",
    "        right_ear = self.eye_aspect_ratio(right_eye)\n",
    "\n",
    "        #Set start time of closed eye\n",
    "        if left_ear < self.ear_threshold:\n",
    "            if self.left_eye_closed_start is None:\n",
    "                self.left_eye_closed_start = current_time\n",
    "        else:\n",
    "            self.left_eye_closed_start = None\n",
    "\n",
    "        if right_ear < self.ear_threshold:\n",
    "            if self.right_eye_closed_start is None:\n",
    "                self.right_eye_closed_start = current_time\n",
    "        else:\n",
    "            self.right_eye_closed_start = None\n",
    "\n",
    "        #Calculate duration of closed eyes\n",
    "        if self.left_eye_closed_start:\n",
    "            self.left_eye_closed_duration = current_time - self.left_eye_closed_start\n",
    "        else:\n",
    "            self.left_eye_closed_duration = 0\n",
    "\n",
    "        if self.right_eye_closed_start:\n",
    "            self.right_eye_closed_duration = current_time - self.right_eye_closed_start\n",
    "        else:\n",
    "            self.right_eye_closed_duration = 0\n",
    "        \n",
    "        #Check for sleepiness\n",
    "        if (self.left_eye_closed_duration > 2 or self.right_eye_closed_duration > 2):\n",
    "            self.eye_closed_duration += 1 \n",
    "        else:\n",
    "            self.eye_closed_duration = 0\n",
    "\n",
    "        return left_ear, right_ear, self.eye_closed_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up MediaPipe Pose model for body pose estimation\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#Initializing drawing utils\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleepines_detector = EyeStateDetector(ear_threshold=0.2)\n",
    "pose_analyzer = PoseAnalyzer(\n",
    "    #Head between 115 and 130 is straight, everything else considered tilt,\n",
    "    head_range=(115,130),hip_angle_threshold=45)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "    \n",
    "    current_time = time.time()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    rgb_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results_pose = pose.process(rgb_frame)\n",
    "    faces = detector(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame,results_pose.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "        landmarks = results_pose.pose_landmarks.landmark\n",
    "\n",
    "        points = {\n",
    "            \"Left Shoulder\": landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "            \"Right Shoulder\": landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "            \"Left Hip\": landmarks[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "            \"Right Hip\": landmarks[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "            \"Left Knee\": landmarks[mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "            \"Right Knee\": landmarks[mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "            \"Nose\": landmarks[mp_pose.PoseLandmark.NOSE],\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "        #Understand if person is standing or not\n",
    "        left_hip_angle,right_hip_angle,is_standing = pose_analyzer.is_standing(\n",
    "            points[\"Left Knee\"],\n",
    "            points[\"Left Hip\"],\n",
    "            points[\"Left Shoulder\"],\n",
    "            points[\"Right Knee\"],\n",
    "            points[\"Right Hip\"],\n",
    "            points[\"Right Shoulder\"]\n",
    "        )\n",
    "\n",
    "        #Understand if the head is tilted\n",
    "\n",
    "        tilt_angle, is_tilted = pose_analyzer.is_head_tilted(\n",
    "            points[\"Left Shoulder\"],\n",
    "            points[\"Right Shoulder\"],\n",
    "            points[\"Nose\"]\n",
    "        )\n",
    "\n",
    "        #Print our metrics and conclusions in the top left border of the screen\n",
    "        cv2.putText(frame, f'Left Hip Angle: {int(left_hip_angle)}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Right Hip Angle: {int(right_hip_angle)}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Is Standing: {is_standing}', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Head Tilt Angle: {int(tilt_angle)}', (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, f'Head Tilted: {is_tilted}', (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "  \n",
    "        ##Print identified landmarks. Not needed, more to just see what the model is \"seeing\"\n",
    "        for point_name, point in points.items():\n",
    "            x,y = int(point.x * frame.shape[1]), int(point.y * frame.shape[0])\n",
    "            cv2.circle(frame,(x,y),5,(0,255,0),-1)\n",
    "            cv2.putText(frame,point_name, (x,y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "\n",
    "    if faces:\n",
    "        for face in faces:\n",
    "            landmarks = predictor(rgb_frame,face)\n",
    "\n",
    "            right_eye = [\n",
    "                (landmarks.part(i).x,landmarks.part(i).y)\n",
    "                for i in range(36,42)\n",
    "            ]\n",
    "\n",
    "            left_eye = [\n",
    "                (landmarks.part(i).x,landmarks.part(i).y)\n",
    "                for i in range(42,48)\n",
    "            ]\n",
    "\n",
    "            left_ear,right_ear = sleepines_detector.update_eye_status(left_eye,right_eye,current_time)\n",
    "\n",
    "\n",
    "            cv2.putText(frame, f\"Left EAR: {left_ear:.2f}\", (50, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Right EAR: {right_ear:.2f}\", (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "            x1,y1,x2,y2 = (face.left(),face.top(),face.right(),face.bottom())\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Pose & Face Landmarks\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### For a proper sleepiness detector we need to consider the factor time more. \n",
    "### Example: a person yawned once in the last minute and has a certain head tilted angle. \n",
    "### If a person is standing and has the eyes closed, it could for example be that they are standing in the sun and enjoying it. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
