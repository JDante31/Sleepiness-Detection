{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install Dependencies\n",
    "import cv2 \n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dlib\n",
    "import time\n",
    "from scipy.spatial import distance\n",
    "\n",
    "\n",
    "####Required file downloads: \n",
    "### URL: https://github.com/italojs/facial-landmarks-recognition/blob/master/shape_predictor_68_face_landmarks.dat\n",
    "### Save file in same folder as this file. Do not use a subfolder. If you do, adjust the file path.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the class pose analyser. Its purpose is to calculate are relevant metrics to understand a person's pose (e.g. Head Tilted, Sitting/STanding)\n",
    "class PoseAnalyzer:\n",
    "\n",
    "    #The head range values are so far only based on the sample of one person. More analysis would be needed to make this very precise. \n",
    "    def __init__(self,head_range=(115,130),hip_angle_threshold=45):\n",
    "        self.head_range = head_range\n",
    "        self.hip_angle_threshold = hip_angle_threshold\n",
    "\n",
    "    #For further development, consider making this a static method in case other classes also need to access the function. \n",
    "    def calculate_angle(self,a,b,c):\n",
    "        ab = np.array([a.x-b.x,a.y-b.y])\n",
    "        bc = np.array([b.x-c.x,b.y-c.y])\n",
    "\n",
    "        dot_product = np.dot(ab,bc)\n",
    "        magnitude_ab = np.linalg.norm(ab)\n",
    "        magnitude_bc = np.linalg.norm(bc)\n",
    "\n",
    "        cos_angle = dot_product / (magnitude_ab * magnitude_bc)\n",
    "    \n",
    "        angle = np.arccos(np.clip(cos_angle,-1.0,1.0))\n",
    "        angle_deg = np.degrees(angle)\n",
    "\n",
    "        return angle_deg\n",
    "    \n",
    "    \n",
    "    def is_head_tilted(self,shoulder_left,shoulder_right,nose):\n",
    "        #Check if landmarks are visible on screen, if not dont calculate the values. \n",
    "        if (not self._is_landmark_visible(shoulder_left) or \n",
    "            not self._is_landmark_visible(shoulder_right) or \n",
    "            not self._is_landmark_visible(nose)):\n",
    "            return None, False\n",
    "\n",
    "        #Checks if head is tilted, based on the range we consider not tilted\n",
    "        tilt_angle = self.calculate_angle(shoulder_left,shoulder_right,nose)\n",
    "        is_tilted = not (self.head_range[0] <= tilt_angle <= self.head_range[1])\n",
    "        return tilt_angle, is_tilted\n",
    "\n",
    "\n",
    "    def is_standing(self,knee_left,hip_left,shoulder_left,knee_right,hip_right,shoulder_right):\n",
    "        #Check if landmarks are visible on screen, if not dont calculate the values. \n",
    "        if (not self._is_landmark_visible(knee_left) or \n",
    "            not self._is_landmark_visible(hip_left) or \n",
    "            not self._is_landmark_visible(shoulder_left) or\n",
    "            not self._is_landmark_visible(knee_right) or \n",
    "            not self._is_landmark_visible(hip_right) or \n",
    "            not self._is_landmark_visible(shoulder_right)):\n",
    "            return None, None, False\n",
    "\n",
    "        # Calculate hip angles\n",
    "        left_hip_angle = self.calculate_angle(knee_left,hip_left,shoulder_left)\n",
    "        right_hip_angle = self.calculate_angle(knee_right,hip_right,shoulder_right)\n",
    "        # Check if person is standing based on hip angles\n",
    "        is_standing = left_hip_angle < self.hip_angle_threshold and right_hip_angle < self.hip_angle_threshold\n",
    "        return left_hip_angle, right_hip_angle, is_standing\n",
    "\n",
    "    def _is_landmark_visible(self, landmark, visibility_threshold=0.5):\n",
    "        # Check if landmark is visible and has a confidence above threshold\n",
    "        # Default visibility_threshold can be adjusted\n",
    "        return landmark is not None and landmark.visibility > visibility_threshold\n",
    "\n",
    "\n",
    "class EyeStateDetector:\n",
    "\n",
    "    def __init__(self,ear_threshold):\n",
    "        self.ear_threshold = ear_threshold\n",
    "        self.left_eye_closed_start = None\n",
    "        self.right_eye_closed_start = None\n",
    "        self.left_eye_closed_duration = 0\n",
    "        self.right_eye_closed_duration = 0\n",
    "        self.eye_closed_duration = 0\n",
    "\n",
    "    def eye_aspect_ratio(self,eye):\n",
    "        #Vertical landmarks\n",
    "        A = distance.euclidean(eye[1],eye[5])\n",
    "        B = distance.euclidean(eye[2],eye[4])\n",
    "        #Horizontal landmarks\n",
    "        C = distance.euclidean(eye[0],eye[3])\n",
    "        ea_ratio = (A+B)/(2*C)\n",
    "        return ea_ratio\n",
    "\n",
    "    def update_eye_status(self,left_eye,right_eye,current_time):\n",
    "       \n",
    "        #Calculate EAR for both eyes\n",
    "        left_ear = self.eye_aspect_ratio(left_eye)\n",
    "        right_ear = self.eye_aspect_ratio(right_eye)\n",
    "\n",
    "        #Set start time of closed eye\n",
    "        if left_ear < self.ear_threshold:\n",
    "            if self.left_eye_closed_start is None:\n",
    "                self.left_eye_closed_start = current_time\n",
    "        else:\n",
    "            self.left_eye_closed_start = None\n",
    "\n",
    "        if right_ear < self.ear_threshold:\n",
    "            if self.right_eye_closed_start is None:\n",
    "                self.right_eye_closed_start = current_time\n",
    "        else:\n",
    "            self.right_eye_closed_start = None\n",
    "\n",
    "        #Calculate duration of closed eyes\n",
    "        if self.left_eye_closed_start:\n",
    "            self.left_eye_closed_duration = current_time - self.left_eye_closed_start\n",
    "        else:\n",
    "            self.left_eye_closed_duration = 0\n",
    "\n",
    "        if self.right_eye_closed_start:\n",
    "            self.right_eye_closed_duration = current_time - self.right_eye_closed_start\n",
    "        else:\n",
    "            self.right_eye_closed_duration = 0\n",
    "        \n",
    "        #Check for sleepiness\n",
    "        if (self.left_eye_closed_duration > 2 or self.right_eye_closed_duration > 2):\n",
    "            self.eye_closed_duration += 1 \n",
    "        else:\n",
    "            self.eye_closed_duration = 0\n",
    "\n",
    "        return left_ear, right_ear, self.eye_closed_duration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up MediaPipe Pose model for body pose estimation\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "#This file is a required download. \n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "\n",
    "#Initializing drawing utils\n",
    "mp_drawing = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "eye_analyzer = EyeStateDetector(ear_threshold=0.2)\n",
    "pose_analyzer = PoseAnalyzer(\n",
    "    #Head between 115 and 130 is straight, everything else considered tilt,\n",
    "    head_range=(117,125),hip_angle_threshold=45)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame\")\n",
    "    \n",
    "    current_time = time.time()\n",
    "    frame = cv2.flip(frame,1)\n",
    "    rgb_frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    results_pose = pose.process(rgb_frame)\n",
    "    faces = detector(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "\n",
    "        mp_drawing.draw_landmarks(frame,results_pose.pose_landmarks,mp_pose.POSE_CONNECTIONS)\n",
    "        landmarks = results_pose.pose_landmarks.landmark\n",
    "\n",
    "        points = {\n",
    "            \"Left Shoulder\": landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER],\n",
    "            \"Right Shoulder\": landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER],\n",
    "            \"Left Hip\": landmarks[mp_pose.PoseLandmark.LEFT_HIP],\n",
    "            \"Right Hip\": landmarks[mp_pose.PoseLandmark.RIGHT_HIP],\n",
    "            \"Left Knee\": landmarks[mp_pose.PoseLandmark.LEFT_KNEE],\n",
    "            \"Right Knee\": landmarks[mp_pose.PoseLandmark.RIGHT_KNEE],\n",
    "            \"Nose\": landmarks[mp_pose.PoseLandmark.NOSE],\n",
    "\n",
    "        }\n",
    "\n",
    "        #Understand if person is standing or not\n",
    "        left_hip_angle,right_hip_angle,is_standing = pose_analyzer.is_standing(\n",
    "            points[\"Left Knee\"],\n",
    "            points[\"Left Hip\"],\n",
    "            points[\"Left Shoulder\"],\n",
    "            points[\"Right Knee\"],\n",
    "            points[\"Right Hip\"],\n",
    "            points[\"Right Shoulder\"]\n",
    "        )\n",
    "\n",
    "        #Understand if the head is tilted\n",
    "        head_tilt_result = pose_analyzer.is_head_tilted(\n",
    "            points[\"Left Shoulder\"],\n",
    "            points[\"Right Shoulder\"],\n",
    "            points[\"Nose\"]\n",
    "        )\n",
    "\n",
    "        # Unpack the result safely \n",
    "        tilt_angle, is_tilted = head_tilt_result if head_tilt_result[0] is not None else (None, False)\n",
    "\n",
    "        if  eye_analyzer.eye_closed_duration > 1 and not is_standing:  # Check for closed eyes regardless of head tilt\n",
    "            final_decision = \"Sleepy\"\n",
    "        elif is_tilted and eye_analyzer.eye_closed_duration > 0.1:  # Check for head tilt and closed eyes\n",
    "            final_decision = \"Sleepy\"\n",
    "        else:\n",
    "            final_decision = \"Not sleepy\"\n",
    "\n",
    "        #Print our metrics and conclusions in the top left border of the screen\n",
    "        #This is mainly used for testing purposes, during the development of this project. For production, the printing, except the sleepy state (final_decision) can be deleted\n",
    "        if left_hip_angle is not None and right_hip_angle is not None:\n",
    "            cv2.putText(frame, f'Left Hip Angle: {int(left_hip_angle)}', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Right Hip Angle: {int(right_hip_angle)}', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Is Standing: {is_standing}', (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, 'Left Hip Angle: N/A', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            cv2.putText(frame, 'Right Hip Angle: N/A', (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        if head_tilt_result is not None:\n",
    "            cv2.putText(frame, f'Head Tilt Angle: {int(tilt_angle)}', (50, 200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f'Head Tilted: {is_tilted}', (50, 250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        cv2.putText(frame, f'State: {final_decision}', (50, 450), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        ##Print identified landmarks. Not needed, more to just see what the model is \"seeing\"\n",
    "        for point_name, point in points.items():\n",
    "            x,y = int(point.x * frame.shape[1]), int(point.y * frame.shape[0])\n",
    "            cv2.circle(frame,(x,y),5,(0,255,0),-1)\n",
    "            cv2.putText(frame,point_name, (x,y),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "\n",
    "    if faces:\n",
    "        for face in faces:\n",
    "            landmarks = predictor(rgb_frame,face)\n",
    "            right_eye = [\n",
    "                (landmarks.part(i).x,landmarks.part(i).y)\n",
    "                for i in range(36,42)\n",
    "            ]\n",
    "            left_eye = [\n",
    "                (landmarks.part(i).x,landmarks.part(i).y)\n",
    "                for i in range(42,48)\n",
    "            ]\n",
    "\n",
    "            left_ear,right_ear,eye_closed_duration = eye_analyzer.update_eye_status(left_eye,right_eye,current_time)\n",
    "            cv2.putText(frame, f\"Left EAR: {left_ear:.2f}\", (50, 300), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f\"Right EAR: {right_ear:.2f}\", (50, 350), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            cv2.putText(frame, f'Eyes closed: {eye_closed_duration}', (50, 400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "            x1,y1,x2,y2 = (face.left(),face.top(),face.right(),face.bottom())\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "    cv2.imshow(\"Pose & Face Landmarks\",frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
